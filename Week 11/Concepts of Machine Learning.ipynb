{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Concepts of Machine Learning\n",
    "\n",
    "많은 문헌에서 Machine Learning을 알고리즘 혹은 Computer Science의 일부로 해석하는 경우가 많다. 하지만 Machine Learning은 기본적으로 통계학을 근간으로 하는 Statistical Learning Model이다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Review OLS Models\n",
    "\n",
    "**Simple Linear Model**\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, ~~~~~ \\epsilon_i \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "Simple Linear Model은 설명변수가 하나이고 종속변수가 하나인 단일 회귀 모형이다. 여기서 $\\epsilon_i$는 오차인데, 오차는 평균이 0이고 분산이 $\\sigma^2$인 정규분포를 따른다고 가정한다\n",
    "\n",
    "이 경우 추정해야 하는 Parameter는 bias로 해석되는 $\\beta_0$과 회귀계수인 $\\beta_1$, 오차항의 분산인 $\\sigma^2$으로 총 3개이다\n",
    "\n",
    "한편, 단순회귀모형을 Network Model로 표현할 경우 다음과 같이 표현 가능하다\n",
    "\n",
    "<center>\n",
    "\n",
    "![SimpleRegression.png](Images/SimpleRegression.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "즉, 가중치가 $\\beta_1$이고 bias가 $\\beta_0$인 Linear Machine Learning Model과 같다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Multiple Linear Model**\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i, ~~~~~ \\epsilon_i \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "Multiple Linear Model은 설명변수가 두개 이상이고 종속변수가 하나인 다중 회귀 모형이다. 마찬가지로 오차는 평균이 0이고 분산이 $\\sigma^2$인 정규분포를 따른다고 가정한다\n",
    "\n",
    "이 경우 Parameter는 bias로 해석되는 $\\beta_0$과 회귀계수인 $\\beta_1, \\beta_2$, 오차항의 분산인 $\\sigma^2$으로 총 4개이다\n",
    "\n",
    "설명변수가 하나씩 증가할수록 추정해야 하는 parameter는 1개씩 늘어나며, 이에 따라 회귀모형의 **자유도(degree of freedom) 또한 하나씩 증가**한다\n",
    "\n",
    "한편, 다중회귀모형을 Network Model로 표현할 경우 다음과 같이 표현 가능하다\n",
    "\n",
    "<center>\n",
    "\n",
    "![MultiLinear.png](Images/MultipleLinearModel.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "즉, 가중치가 각각 $\\beta_1, \\beta_2$이고 bias가 $\\beta_0$인 Linear Machine Learning Model과 같다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Multinomial Linear Model**\n",
    "\n",
    "$$\\begin{pmatrix} y_{1i} \\\\ y_{2i} \\end{pmatrix} = \\begin{pmatrix} \\beta_{10} \\\\ \\beta_{20} \\end{pmatrix} + \n",
    "\\begin{pmatrix} \\beta_{11} & \\beta_{12} \\\\ \\beta_{21} & \\beta_{22} \\end{pmatrix} \\begin{pmatrix} x_{1i} \\\\ x_{2i} \\end{pmatrix} +\n",
    "\\begin{pmatrix} \\epsilon_{1i} \\\\ \\epsilon_{2i} \\end{pmatrix}, ~~~~~ \n",
    "\\begin{pmatrix} \\epsilon_{1i} \\\\ \\epsilon_{2i} \\end{pmatrix} \\sim N\\Big(0, \\begin{pmatrix} \\sigma_{11} & \\sigma_{12} \\\\ \\sigma_{21} & \\sigma_{22} \\end{pmatrix}\\Big)$$\n",
    "\n",
    "Multinomial Linear Model은 설명변수가 두개 이상이고 종속변수도 두 개 이상인 다변량 회귀 모형이다. \n",
    "\n",
    "오차항은 Gaussian 계열 분포를 따르고, 분산은 $\\Sigma^2$로 생각하면 된다. 다변량 정규분포의 이점은 두 관측집단간 **공분산**이 추정된다는 것이다\n",
    "\n",
    "한편, 다변량 회귀모형을 Network Model로 표현할 경우 다음과 같이 표현 가능하다\n",
    "\n",
    "<center>\n",
    "\n",
    "![multinomial.png](Images/multinomial.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "즉, 가중치가 각각 $\\beta_1, \\beta_2$이고 bias가 $\\beta_0$인 MultiClass Machine Learning Model과 같다. 사실, 이제까지 배운 모든 시계열 모형들 또한 위와같이 표현이 가능한 것이다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Neural Network\n",
    "\n",
    "Neural Network는 Layer가 두 개 이상인 모형을 의미한다. Layer가 심층적으로 쌓인 경우, Deep Neural Network라고 한다\n",
    "\n",
    "<center>\n",
    "\n",
    "![nn.png](Images/neural.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "Neural Network에서는 계수(Coefficient)보다는 가중치(Weights)로 더 많이 통용된다. 추정하는 가중치 parameter는 결국 선형모형에서 Coefficient를 추정하는것과 같다.\n",
    "\n",
    "**활성화 함수(Activation Function)** 는 통계학에서의 연결 함수의 개념을 차용한 것이다. \n",
    "\n",
    "대표적인 연결 함수로는 log, sigmoid, logistic이 존재하는데, 이중 sigmoid와 logistic은 초창기 Neural Network model의 활성화 함수로 사용된 것이다\n",
    "\n",
    "한편, sklearn library에서는 `neural_network.MLPClassifier`, `neural_network.MLPRegressor`를 이용해 Neural Network를 구현할 수 있다\n",
    "\n",
    "```\n",
    "sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, \n",
    "                                     solver='adam', alpha=0.0001, \n",
    "                                     learning_rate='constant', \n",
    "                                     learning_rate_init=0.001, \n",
    "                                     max_iter=200, shuffle=True, \n",
    "                                     random_state=None, \n",
    "                                     arly_stopping=False)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
